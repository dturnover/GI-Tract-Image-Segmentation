{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa964f10",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d15254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef164ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_to_binary(rle, shape): \n",
    "    # create array of zeros representing a blank mask\n",
    "    mask = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    \n",
    "    # split rle string into list\n",
    "    s = rle.split()\n",
    "    \n",
    "    # convert the starts and lengths to numpy arrays of integers\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]\n",
    "    \n",
    "    # subtract 1 from the starts since RLE encoding is 1-index and python uses 0-indexing\n",
    "    starts -= 1\n",
    "    \n",
    "    # calculate the end positions of each continuous sequence by adding the lengths to their respective starts (ends = starts + lengths)\n",
    "    for start, length in zip(starts, lengths):\n",
    "        mask[start:start+length] = 1\n",
    "      \n",
    "    # reshape the 1D array to the desired 2D output shape\n",
    "    return mask.reshape(shape, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "311783cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiclass_mask(rle_list, original_shape, target_shape):\n",
    "    masks = []\n",
    "    \n",
    "    for rle in rle_list:\n",
    "        # decode he rle mask into a binary mask\n",
    "        mask = rle_to_binary(rle, original_shape)\n",
    "        \n",
    "        # reshape the mask to so that it matches the target\n",
    "        resized = resize(mask, target_shape, preserve_range=True, mode='reflect', anti_aliasing=True)\n",
    "        masks.append(resized)\n",
    "        \n",
    "    return np.stack(masks, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b9cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_datagen(df, dir, batch_size, target_size):\n",
    "    # create the image data generator, for now only normalizing as a preprocessing step\n",
    "    datagen = ImageDataGenerator(rescale=1/255)\n",
    "    \n",
    "    # create a list of unique image ids\n",
    "    ids = np.array(list(df.groups.keys())) ####\n",
    "    \n",
    "    while True:\n",
    "        sample = df.sample(batch_size, replace=True) ############\n",
    "            \n",
    "        images = []\n",
    "        masks = []\n",
    "        \n",
    "        for _, row in sample.iterrows():\n",
    "            # get the dataframe rows for the current image\n",
    "            img_rows = df.get_group(row['id'])\n",
    "            \n",
    "            # extract the rle masks from the rows\n",
    "            rle_list = img_rows['segmentation'].tolist()\n",
    "            \n",
    "            # search the dataset directory for an image matching the image id\n",
    "            sections = row['id'].split('_')\n",
    "            case = sections[0]\n",
    "            day = sections[0] + '_' + sections[1]\n",
    "            slice = sections[2] + '_' + sections[3]\n",
    "            \n",
    "            pattern = os.path.join(dir, case, day, \"scans\", f\"{slice}*.png\")\n",
    "            file = glob.glob(pattern)[0]\n",
    "                        \n",
    "            # load the image and correct its size \n",
    "            original_shape = Image.open(file).size[::-1]\n",
    "            image = load_img(file, target_size=target_size, color_mode='grayscale')\n",
    "            image_array = img_to_array(image)\n",
    "            \n",
    "            # load and decode the multiclass mask and resize it accordingly\n",
    "            mask = create_multiclass_mask(rle_list, original_shape, target_size)\n",
    "            \n",
    "            images.append(image_array)\n",
    "            masks.append(mask)\n",
    "            \n",
    "        x = np.array(images)\n",
    "        y = np.array(masks)\n",
    "        \n",
    "        print(x, y)\n",
    "        \n",
    "        # yield statement allows us to return some data to the caller and if\n",
    "        # called again resume execution from within the while loop\n",
    "        yield datagen.flow(x, y, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53bb9afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unet(input_size, num_classes=3):\n",
    "    input = Input(input_size)\n",
    "    \n",
    "    # contracting\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    # bottleneck\n",
    "    convB = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    convB = Conv2D(256, (3, 3), activation='relu', padding='same')(convB)\n",
    "    \n",
    "    # expanding\n",
    "    up3 = concatenate([UpSampling2D(size=(2, 2))(convB), conv2], axis=-1)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(up3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    \n",
    "    up4 = concatenate([UpSampling2D(size=(2, 2))(conv3), conv1], axis=-1)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)\n",
    "    \n",
    "    output = Conv2D(num_classes, (1, 1), activation='softmax')(conv4)\n",
    "    \n",
    "    return Model(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af47f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file into a dataframe and convert it into a groupby object to keep our images grouped by id\n",
    "df = pd.read_csv('./Dataset/train.csv')\n",
    "df['segmentation'] = df['segmentation'].fillna('0')\n",
    "\n",
    "grouped_df = df.groupby('id')\n",
    "\n",
    "# dataset directory\n",
    "dir = '.\\\\Dataset\\\\train'\n",
    "\n",
    "batch_size = 32\n",
    "target_size = 256\n",
    "\n",
    "# create the training data generator\n",
    "train_generator = custom_datagen(grouped_df, dir, batch_size, (target_size, target_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb04c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\Dataset\\\\train\\\\case123\\\\case123_day20\\\\scans\\\\slice_0001*.png'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = df['id'][0]\n",
    "sections = id.split('_')\n",
    "case_no = sections[0]\n",
    "day = sections[0] + '_' + sections[1]\n",
    "slice = sections[2] + '_' + sections[3]\n",
    "\n",
    "pattern = os.path.join(dir, case_no, day, \"scans\", f\"{slice}*.png\")\n",
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8d9251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the U-net neural network and compile it\n",
    "model = make_unet(input_size=(target_size, target_size, 1), num_classes=3)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acciracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8ce9428",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:933\u001b[0m, in \u001b[0;36mGeneratorDataAdapter._peek_and_restore\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_peek_and_restore\u001b[39m(x):\n\u001b[1;32m--> 933\u001b[0m     peek \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m peek, itertools\u001b[38;5;241m.\u001b[39mchain([peek], x)\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_generator, batch_size=batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e8fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9eb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e109cc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2e45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc95a7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a2f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ddaa608",
   "metadata": {},
   "source": [
    "#### Extract id and image size info from each image filename using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b93b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_names = []\n",
    "\n",
    "for filename in generator.filenames:\n",
    "\n",
    "    # substitute characters so that the slice name matches the csv file\n",
    "    new_fn = re.sub(\"case([0-9]+)\\\\\\\\\", \"\", filename)\n",
    "    new_fn = re.sub(\"\\\\\\\\\", \"_\", new_fn)\n",
    "    new_fn = re.sub(\"_[0-9]{3}_[0-9]{3}_1.50_1.50.png\", \"\", new_fn)\n",
    "\n",
    "    slice_names.append(new_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6aa96fa",
   "metadata": {},
   "source": [
    "#### Display some images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf99108d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 20))\n",
    "\n",
    "images = next(generator)\n",
    "\n",
    "itr = 0\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[i, j].imshow(images[itr])\n",
    "        ax[i, j].title.set_text(slice_names[itr])\n",
    "        itr += 1\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d7609",
   "metadata": {},
   "source": [
    "# Issues\n",
    "### If we reshape an image in the datagen then the mask probably is no longer accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baefc677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
