{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df428a7",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d8e3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, UpSampling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f70985",
   "metadata": {},
   "source": [
    "### Function definitions\n",
    "##### rle_to_binary() decodes the run length encoded mask into a binary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "570873b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_to_binary(rle, shape): \n",
    "    \n",
    "    # create array of zeros representing a blank mask\n",
    "    mask = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    \n",
    "    # split rle string into list\n",
    "    s = rle.split()\n",
    "    \n",
    "    # convert the starts and lengths to numpy arrays of integers\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])] \n",
    "    \n",
    "    # subtract 1 from the starts since RLE encoding is 1-index and python uses 0-indexing\n",
    "    starts -= 1\n",
    "    \n",
    "    # calculate the end positions of each continuous sequence by adding the lengths to their respective starts (ends = starts + lengths)\n",
    "    for start, length in zip(starts, lengths):\n",
    "        mask[start:start+length] = 1\n",
    "      \n",
    "    # reshape the 1D array to the desired 2D output shape\n",
    "    return mask.reshape(shape, order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd5671",
   "metadata": {},
   "source": [
    "##### create_multiclass_mask() decodes each mask for each of the three classes and stacks them into a single multi-channel array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a335053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiclass_mask(rle_list, original_shape, target_shape):\n",
    "    \n",
    "    masks = []\n",
    "    \n",
    "    for rle in rle_list:\n",
    "        # decode he rle mask into a binary mask\n",
    "        mask = rle_to_binary(rle, original_shape)\n",
    "        \n",
    "        # reshape the mask to so that it matches the target\n",
    "        resized = resize(mask, target_shape, preserve_range=True, mode='reflect', anti_aliasing=True)\n",
    "        masks.append(resized)\n",
    "        \n",
    "    return np.stack(masks, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa81aced",
   "metadata": {},
   "source": [
    "#### custom_datagen() creates a custom image data generator that can simultaneously preprocess each image alongside its target masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28abe8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_datagen(gdf, dir, batch_size, target_size):\n",
    "    \n",
    "    # create the image data generator, for now only normalizing as a preprocessing step\n",
    "    datagen = ImageDataGenerator(rescale=1/255)\n",
    "    \n",
    "    # create a list of unique image ids\n",
    "    ids = list(gdf.groups.keys())\n",
    "    \n",
    "    while True:\n",
    "            \n",
    "        sample_ids = np.random.choice(ids, size=batch_size, replace=False)\n",
    "            \n",
    "        images = []\n",
    "        masks = []\n",
    "        \n",
    "        for id in sample_ids:\n",
    "            # get the dataframe rows for the current image\n",
    "            img_rows = gdf.get_group(id)\n",
    "            \n",
    "            # extract the rle masks from the rows\n",
    "            rle_list = img_rows['segmentation'].tolist()\n",
    "            \n",
    "            # search the dataset directory for an image matching the image id\n",
    "            sections = id.split('_')\n",
    "            case = sections[0]\n",
    "            day = sections[0] + '_' + sections[1]\n",
    "            slice = sections[2] + '_' + sections[3]\n",
    "            \n",
    "            pattern = os.path.join(dir, case, day, \"scans\", f\"{slice}*.png\")\n",
    "            file = glob.glob(pattern)[0]\n",
    "                        \n",
    "            # load the image and correct its size \n",
    "            original_shape = Image.open(file).size[::-1]\n",
    "            image = load_img(file, target_size=target_size, color_mode='grayscale')\n",
    "            image_array = img_to_array(image)\n",
    "            \n",
    "            # load and decode the multiclass mask and resize it accordingly\n",
    "            mask = create_multiclass_mask(rle_list, original_shape, target_size)\n",
    "            \n",
    "            images.append(image_array)\n",
    "            masks.append(mask)\n",
    "            \n",
    "        x = np.array(images)\n",
    "        y = np.array(masks)\n",
    "                \n",
    "        # yield statement allows us to return some data to the caller and if\n",
    "        # called again resume execution from within the while loop\n",
    "        yield datagen.flow(x, y, batch_size=batch_size).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af410114",
   "metadata": {},
   "source": [
    "#### make_unet() builds the U-Net architecture and returns the model. It consists of an encoder of contracting convolutional layers, a bottleneck, and a decoder which upsamples and concatenates previous layers. The output layer is softmax since we are classifying every pixel in the image. Within this framework we can add and subtract layers as well as experiment with different activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1e4817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_unet(input_size, num_classes=3):\n",
    "    \n",
    "    input = Input(input_size)\n",
    "    \n",
    "    # contracting\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(input)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    # bottleneck\n",
    "    convB = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    convB = Conv2D(256, (3, 3), activation='relu', padding='same')(convB)\n",
    "    \n",
    "    # expanding\n",
    "    up3 = concatenate([UpSampling2D(size=(2, 2))(convB), conv2], axis=-1)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(up3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    \n",
    "    # concatenate operations on the expanding section combine feature maps from earlier layers\n",
    "    up4 = concatenate([UpSampling2D(size=(2, 2))(conv3), conv1], axis=-1)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)\n",
    "    \n",
    "    output = Conv2D(num_classes, (1, 1), activation='softmax')(conv4)\n",
    "    \n",
    "    return Model(inputs=input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a5ec87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file into a dataframe and convert it into a groupby object to keep our images grouped by id\n",
    "df = pd.read_csv('./Dataset/train.csv')\n",
    "df['segmentation'] = df['segmentation'].fillna('0')\n",
    "\n",
    "grouped_df = df.groupby('id')\n",
    "\n",
    "# dataset directory\n",
    "dir = '.\\\\Dataset\\\\train'\n",
    "\n",
    "batch_size = 32\n",
    "target_size = 256\n",
    "\n",
    "# create the training data generator\n",
    "train_generator = custom_datagen(grouped_df, dir, batch_size, (target_size, target_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a1a8ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the U-net neural network and compile it\n",
    "model = make_unet(input_size=(target_size, target_size, 1), num_classes=3)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8dc551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "      6/Unknown - 157s 25s/step - loss: 0.3011 - accuracy: 0.1936"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator, batch_size=batch_size, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c54837f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d0bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3742b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe26ccd9",
   "metadata": {},
   "source": [
    "#### Display some images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dca139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 20))\n",
    "\n",
    "images = next(train_generator)\n",
    "\n",
    "itr = 0\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[i, j].imshow(images[itr])\n",
    "        ax[i, j].title.set_text(slice_names[itr])\n",
    "        itr += 1\n",
    "        \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
